name: FINAL - M3U8 URL Scraper

on:
  workflow_dispatch:
    inputs:
      page_url:
        description: 'URL of the page to scrape the stream from'
        required: true
        default: 'https://www.redditsoccerstreams.name/hd-10/'

jobs:
  scrape-url:
    runs-on: ubuntu-latest
    timeout-minutes: 5 # The job will time out after 5 minutes if no URL is found

    steps:
    - name: 1. Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y --no-install-recommends wget nodejs npm
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt-get install -y ./google-chrome-stable_current_amd64.deb || true
        rm google-chrome-stable_current_amd64.deb

    - name: 2. Scrape for .m3u8 URL
      run: |
        # Install puppeteer
        npm i puppeteer

        # Create the advanced scraper script (scraper.js)
        cat <<'EOF' > scraper.js
        const puppeteer = require('puppeteer');

        const PAGE_URL = process.env.PAGE_URL;
        let urlFound = false;

        (async () => {
          console.log('üöÄ Launching browser to sniff network traffic...');
          const browser = await puppeteer.launch({
            headless: 'new', // Use the new, more stable headless mode
            executablePath: '/usr/bin/google-chrome',
            args: ['--no-sandbox', '--disable-gpu', '--disable-dev-shm-usage']
          });

          const page = await browser.newPage();
          const client = await page.target().createCDPSession();
          await client.send('Network.enable');

          console.log('‚úÖ Network listener attached.');

          // Listen for all network requests
          client.on('Network.requestWillBeSent', (event) => {
            const url = event.request.url;

            // If we find the m3u8 URL and haven't already found one
            if (url.includes('.m3u8') && !urlFound) {
              urlFound = true;
              console.log('‚úÖ SUCCESS! Found the .m3u8 stream URL:');
              console.log('================================================================');
              console.log(url); // Print the raw URL
              console.log('================================================================');
              
              // Close the browser and exit successfully
              browser.close();
              process.exit(0);
            }
          });

          console.log(` Navigating to: ${PAGE_URL}`);
          await page.goto(PAGE_URL, { waitUntil: 'networkidle2', timeout: 60000 });

          console.log('‚úÖ Page loaded. Clicking body to trigger video player...');
          try {
            await new Promise(resolve => setTimeout(resolve, 5000));
            await page.click('body');
            console.log('‚úÖ Click sent.');
          } catch (error) {
            console.error('Could not click page, but listener is still active.');
          }
          
          // Wait for a while to give the page time to find the m3u8 file
          console.log('‚è≥ Waiting for up to 90 seconds to detect the stream URL...');
          await new Promise(resolve => setTimeout(resolve, 90000));

          // If after 90 seconds, nothing was found, exit with an error
          if (!urlFound) {
            console.error('‚ùå FAILED: Timed out. Could not find any .m3u8 stream URL on this page.');
            await browser.close();
            process.exit(1);
          }
        })();
        EOF

        # Run the scraper script with the URL from the workflow input
        node scraper.js
      env:
        PAGE_URL: ${{ github.event.inputs.page_url }}
